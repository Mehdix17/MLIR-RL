from dotenv import load_dotenv

# Load environment variables
load_dotenv(override=True)
load_dotenv('.env.debug')

import os
import logging
import torch
import json
from rl_autoschedular.benchmarks import Benchmarks
from rl_autoschedular.execution import Execution
from rl_autoschedular.model import HiearchyModel as Model
from rl_autoschedular import device
from rl_autoschedular.trajectory import TrajectoryData
from rl_autoschedular.ppo import collect_trajectory, ppo_update, value_update, evaluate_benchmarks
from utils.log import print_info, print_success
from utils.config import Config
from utils.dask_manager import DaskManager
from utils.file_logger import FileLogger
from typing import Optional
from time import time
from datetime import timedelta

logging.basicConfig(
    filename=f"logs/{os.getenv('SLURM_JOB_NAME', 'interactive')}_{os.environ['SLURM_JOB_ID']}.debug",
    filemode="w",
    format="${asctime} - [${levelname}]    ${name}: ${message}",
    datefmt="%m-%d %H:%M",
    style='$',
    level=logging.DEBUG
)

# Initialize singleton classes
cfg = Config()
fl = FileLogger()
dm = DaskManager()


# Data loading
def load_train_data():
    return Benchmarks()


def load_eval_data():
    return Benchmarks(is_training=False)


def load_main_exec_data() -> Optional[dict[str, dict[str, int]]]:
    main_exec_data = None
    if Config().main_exec_data_file:
        with open(Config().main_exec_data_file) as f:
            main_exec_data = json.load(f)
    return main_exec_data


train_data = dm.run_and_register_to_workers(load_train_data)
eval_data = dm.run_and_register_to_workers(load_eval_data)
main_exec_data = dm.run_and_register_to_workers(load_main_exec_data)

# Initialize execution singleton
Execution(fl.exec_data_file, main_exec_data)

print_info(f"Config: {cfg}")
print_success(f'Logging to: {fl.run_dir}')
if cfg.main_exec_data_file:
    print_info(f"Global execution data located in: {cfg.main_exec_data_file}")

# Setup torch
torch.set_grad_enabled(False)
torch.set_num_threads(4)
if cfg.debug:
    torch.autograd.set_detect_anomaly(True)

# Validate model configuration
if cfg.model_type == "distilbert":
    print_info("Using DistilBERT model - validating configuration...")
    from rl_autoschedular.observation import OpFeatures
    
    # Check if feature sizes are reasonable for tokenization
    op_feature_size = OpFeatures.size()
    print_info(f"  Operation feature size: {op_feature_size}")
    print_info(f"  Tokenizer will create sequences of ~{op_feature_size * 2 + 2} tokens")
    
    # Warn if sequences might be very long
    if op_feature_size * 2 + 2 > 100:
        print_info(f"  ⚠️  Large feature size may result in long sequences")
        print_info(f"     Consider increasing max_seq_length in tokenizer if needed")
    
    print_success("DistilBERT configuration validated")
elif cfg.model_type == "lstm":
    print_info("Using LSTM model (default)")
else:
    raise ValueError(f"Unknown model type: {cfg.model_type}")

# Initiate model
model = Model().to(device)
optimizer = torch.optim.Adam(
    model.parameters(),
    lr=cfg.lr
)
print_success("Model initialized")

# Start training
old_trajectory: Optional[TrajectoryData] = None
iter_time_dlt = 0
elapsed_dlt = 0
eta_dlt = 0
overall_start = time()
for step in range(cfg.nb_iterations):
    print_info(
        f"- Main Loop {step + 1}/{cfg.nb_iterations}"
        f" ({100 * (step + 1) / cfg.nb_iterations:.2f}%)"
        f" ({iter_time_dlt}/it) ({elapsed_dlt} < {eta_dlt})",
        flush=True
    )

    main_start = time()

    # Collect trajectory using the model
    print_info(f"Starting trajectory collection (train_data has {len(train_data)} benchmarks)...")
    trajectory = collect_trajectory(train_data, model, step)
    print_info(f"Trajectory collection complete!")

    # Extend trajectory with previous trajectory
    if cfg.reuse_experience != 'none':
        reuse_start = time()
        if old_trajectory is not None:
            trajectory = old_trajectory + trajectory
        old_trajectory = trajectory.copy()
        reuse_end = time()
        reuse_time_ms = int((reuse_end - reuse_start) * 1000)
        print_info(f"Reuse time: {reuse_time_ms}ms")

    # Fit value model to trajectory rewards
    if cfg.value_epochs > 0:
        value_update(trajectory, model, optimizer)

    # Update policy model with PPO
    ppo_update(trajectory, model, optimizer)

    # Save the model
    if (step + 1) % 5 == 0:
        torch.save(
            model.state_dict(),
            os.path.join(
                fl.models_dir,
                f'model_{step}.pt'
            )
        )

    if (step + 1) % 100 == 0:
        print_info('- Evaluating benchmarks -')
        evaluate_benchmarks(model, eval_data)

    main_end = time()
    iter_time = main_end - main_start
    elapsed = main_end - overall_start
    eta = elapsed * (cfg.nb_iterations - step - 1) / (step + 1)
    iter_time_dlt = timedelta(seconds=iter_time)
    elapsed_dlt = timedelta(seconds=int(elapsed))
    eta_dlt = timedelta(seconds=int(eta))

if (step + 1) % 100 != 0:
    print_info('- Evaluating benchmarks -')
    evaluate_benchmarks(model, eval_data)

# Training complete - sync to Neptune
print_success("Training complete!")
print_info(f"Results saved to: {fl.run_dir}")

# Auto-sync to Neptune if configured
if os.getenv('NEPTUNE_PROJECT') and os.getenv('NEPTUNE_TOKEN'):
    print_info("Syncing results to Neptune...")
    try:
        import subprocess
        sync_script = os.path.join(os.path.dirname(__file__), '..', 'experiments', 'sync_neptune_with_plots.py')
        result = subprocess.run(
            ['python', sync_script, fl.run_dir],
            capture_output=True,
            text=True,
            timeout=300  # 5 minute timeout
        )
        if result.returncode == 0:
            print_success("✓ Successfully synced to Neptune!")
            print(result.stdout)
        else:
            print(f"⚠ Neptune sync failed (exit code {result.returncode})")
            print(result.stderr)
    except subprocess.TimeoutExpired:
        print("⚠ Neptune sync timed out (>5 minutes)")
    except Exception as e:
        print(f"⚠ Neptune sync error: {e}")
else:
    print_info("Neptune sync skipped (NEPTUNE_PROJECT or NEPTUNE_TOKEN not set)")
    print_info(f"To sync manually: python experiments/sync_neptune_with_plots.py {fl.run_dir}")
