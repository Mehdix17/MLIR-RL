"""
Organize data folder to integrate new generation with existing structure
"""

import shutil
from pathlib import Path
import json


def main():
    print("ðŸ”§ Organizing data structure...\n")
    
    base_dir = Path("data")
    
    # 1. Create new subdirectories
    print("1. Creating new directories...")
    new_dirs = [
        ("generated/code_files", "Additional randomly generated MLIR programs"),
        ("generated/train", "Training augmentation data"),
        ("generated/eval", "Evaluation augmentation data"),
        ("neural_nets/resnet", "ResNet family converted to MLIR"),
        ("neural_nets/bert", "BERT/Transformer models"),
        ("neural_nets/custom", "Custom neural networks"),
        ("data/benchmarks/single_ops", "Single operation benchmarks"),
        ("data/benchmarks/neural_nets", "Full neural network benchmarks"),
    ]
    
    for dir_path, description in new_dirs:
        full_path = base_dir / dir_path
        full_path.mkdir(parents=True, exist_ok=True)
        
        # Create README
        readme = full_path / "README.md"
        if not readme.exists():
            with open(readme, 'w') as f:
                f.write(f"# {dir_path.split('/')[-1].title()}\n\n")
                f.write(f"{description}\n\n")
                f.write(f"Generated by: organize_data.py\n")
        
        print(f"  âœ“ {dir_path}")
    
    # 2. Move test files if they exist
    print("\n2. Moving test files...")
    moves = [
        ("test_generation", "generated/test"),
        ("test_nn_conversion", "neural_nets/test"),
    ]
    
    for src, dst in moves:
        src_path = base_dir / src
        dst_path = base_dir / dst
        
        if src_path.exists():
            dst_path.mkdir(parents=True, exist_ok=True)
            for f in src_path.glob("*.mlir"):
                shutil.move(str(f), str(dst_path / f.name))
            if not any(src_path.iterdir()):
                src_path.rmdir()
            print(f"  âœ“ {src} â†’ {dst}")
        else:
            print(f"  - {src} (not found, skipping)")
    
    # 3. Create .gitignore for generated data
    print("\n3. Creating .gitignore files...")
    gitignore_content = """# Generated MLIR files (can be regenerated)
*.mlir

# Keep README and JSON files
!README.md
!*.json
"""
    
    for subdir in ["generated", "neural_nets", "benchmarks"]:
        gitignore_path = base_dir / subdir / ".gitignore"
        with open(gitignore_path, 'w') as f:
            f.write(gitignore_content)
        print(f"  âœ“ {subdir}/.gitignore")
    
    # 4. Print final structure
    print("\n" + "="*60)
    print("âœ… Data structure organized!\n")
    print_structure()
    
    # 5. Statistics
    print("\n" + "="*60)
    print("ðŸ“Š Statistics:\n")
    
    all_dir = base_dir / "all" / "code_files"
    test_dir = base_dir / "test" / "code_files"
    
    existing_all = len(list(all_dir.glob("*.mlir"))) if all_dir.exists() else 0
    existing_test = len(list(test_dir.glob("*.mlir"))) if test_dir.exists() else 0
    
    print(f"  Existing data/all/code_files:    {existing_all} files")
    print(f"  Existing data/test/code_files:   {existing_test} files")
    print(f"  New structure ready for:         500+ augmentation files")
    print(f"  Neural networks supported:       ResNet, BERT, Custom")
    
    print("\n" + "="*60)
    print("\nðŸš€ Next steps:\n")
    print("  1. Generate augmentation data:")
    print("     python scripts/augment_dataset.py")
    print("\n  2. Convert neural networks:")
    print("     python data_generation/nn_to_mlir.py")
    print("\n  3. Train with augmented data:")
    print("     CONFIG_FILE_PATH=config/config.json python bin/train.py")


def print_structure():
    """Print the organized directory structure"""
    structure = """Final Structure:
    
data/
â”œâ”€â”€ all/                          âœ“ EXISTING: Primary training data
â”‚   â”œâ”€â”€ code_files/              (400+ MLIR files)
â”‚   â””â”€â”€ execution_times_*.json
â”‚
â”œâ”€â”€ test/                        âœ“ EXISTING: Test/validation data  
â”‚   â”œâ”€â”€ code_files/
â”‚   â””â”€â”€ execution_times_*.json
â”‚
â”œâ”€â”€ generated/                   âœ“ NEW: Augmentation data
â”‚   â”œâ”€â”€ code_files/             (Additional random MLIR)
â”‚   â”œâ”€â”€ train/                  (Training augmentation)
â”‚   â”œâ”€â”€ eval/                   (Eval augmentation)
â”‚   â”œâ”€â”€ test/                   (Test files from integration)
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ neural_nets/                 âœ“ NEW: Converted networks
â”‚   â”œâ”€â”€ resnet/                 (ResNet-18, 34, 50)
â”‚   â”œâ”€â”€ bert/                   (BERT, DistilBERT)
â”‚   â”œâ”€â”€ custom/                 (User models)
â”‚   â”œâ”€â”€ test/                   (Test files from integration)
â”‚   â””â”€â”€ .gitignore
â”‚
â””â”€â”€ data/benchmarks/                  âœ“ NEW: Evaluation suites
    â”œâ”€â”€ single_ops/             (matmul, conv2d, etc.)
    â”œâ”€â”€ neural_nets/            (End-to-end networks)
    â””â”€â”€ .gitignore

Usage:
  â€¢ data/all/       â†’ Training (existing workflow)
  â€¢ data/generated/ â†’ Augment training data
  â€¢ data/neural_nets/ â†’ Test on real networks
  â€¢ data/benchmarks/ â†’ Evaluation & comparison
"""
    print(structure)


if __name__ == "__main__":
    main()
